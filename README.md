# AI-Knowledge-Base-Chatbot-using-Amazon-Bedrock-RAG
This project is a serverless AI-powered chatbot built on AWS using Amazon Bedrock Knowledge Bases (RAG).
It allows users to ask questions via a web interface and receive grounded, accurate answers based on curated knowledge stored in Bedrock.

ğŸš€ Project Overview

The application uses a Retrieval-Augmented Generation (RAG) architecture:

A static web UI hosted on Amazon S3

A serverless backend using AWS Lambda (Function URL)

Amazon Bedrock Knowledge Base for retrieval

Foundation Model via Amazon Bedrock for response generation

The chatbot answers questions using only the data provided in the Knowledge Base, ensuring accuracy and relevance.

ğŸ—ï¸ Architecture Flow

High-level request flow:

User opens the web UI (S3 static website)

User submits a question

Browser sends a POST request to a Lambda Function URL

Lambda calls Amazon Bedrock RetrieveAndGenerate

Bedrock:

Retrieves relevant content from the Knowledge Base (vector search)

Generates a response using a foundation model

Lambda returns the response to the UI

UI displays the answer to the user

Browser
  â†’ S3 Static Website
    â†’ Lambda Function URL
      â†’ Amazon Bedrock Agent Runtime
        â†’ Knowledge Base (Retrieve)
        â†’ Foundation Model (Generate)
      â†’ Lambda
  â†’ Browser

ğŸ§© AWS Services Used
1ï¸âƒ£ Amazon S3

Hosts the static frontend website (HTML, CSS, JavaScript)

Public static website hosting enabled

Serves the chatbot UI to users

2ï¸âƒ£ AWS Lambda

Acts as the backend API

Exposed via Lambda Function URL (no API Gateway required)

Handles:

CORS

Input validation

Calls to Amazon Bedrock

Response formatting

3ï¸âƒ£ Amazon Bedrock

Provides access to foundation models

Used for text generation

Integrated via Bedrock Agent Runtime

4ï¸âƒ£ Amazon Bedrock Knowledge Base

Stores domain-specific documents

Uses vector embeddings for semantic retrieval

Enables Retrieval-Augmented Generation (RAG)

5ï¸âƒ£ AWS IAM

IAM role attached to Lambda

Least-privilege permissions for:

bedrock:RetrieveAndGenerate

Bedrock model access

Knowledge Base access

ğŸ§  Retrieval-Augmented Generation (RAG)

Instead of sending the question directly to a model, this project uses RAG:

ğŸ” Retrieve: Find relevant content from the Knowledge Base

âœï¸ Generate: Use retrieved content + question to generate a response

ğŸ“š Grounded answers: Reduces hallucinations and improves accuracy

âš™ï¸ Configuration (Environment Variables)

Lambda uses the following environment variables:

BEDROCK_REGION=us-east-2
KNOWLEDGE_BASE_ID=48MNNTPTJF
MODEL_ARN=arn:aws:bedrock:us-east-2::foundation-model/meta.llama3-3-70b-instruct-v1:0

ğŸ–¥ï¸ Frontend Features

Chat-style UI

Example questions for quick testing

Copy response button

Status indicator (online / error)

Timeout handling and error messages

âœ… Key Highlights

Fully serverless

No API Gateway required (uses Lambda Function URL)

Secure, scalable, and cost-efficient

Demonstrates real-world GenAI + AWS integration

Production-ready RAG architecture

ğŸ“Œ Use Cases

Personal portfolio chatbot

Internal knowledge assistant

Resume / profile Q&A bot

Enterprise knowledge base search

ğŸ“ˆ What This Project Demonstrates

AWS serverless architecture

Amazon Bedrock RAG implementation

Knowledge Base integration

Proper region and IAM configuration

Debugging real-world GenAI issues

Frontend â†” backend integration

ğŸ§‘â€ğŸ’» Author

Venkata Srimannarayana Yasam
Software Engineer | AWS Certified Solutions Architect

ğŸ“§ Email: srimannarayana.yasam@gmail.com

ğŸ’¼ LinkedIn: https://www.linkedin.com/in/venkata-srimannarayana-yasam

ğŸ’» GitHub: https://github.com/srimannarayana-yasam
